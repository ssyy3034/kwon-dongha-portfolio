---
date: 2025-10-31
tags: [CS]
---

`malloc` 랩의 Tiny 웹 서버에서는 동시성 구현을 위해 멀티프로세스(`fork()`) 방식을 사용했지만, 프록시와 같은 실제 네트워크 애플리케이션에서는 멀티스레드가 훨씬 더 효율적이기 때문입니다.

---

## 왜 멀티프로세스(`fork`)보다 멀티스레드를 선호할까요?

프록시의 역할은 클라이언트와 서버 사이에서 데이터를 '중계'하는 것입니다. 이 과정에서 스레드 방식은 프로세스 방식에 비해 3가지 결정적인 장점을 가집니다.

### 1. 자원 생성 비용 (Resource Creation Cost) 🚀

새로운 클라이언트 요청이 들어올 때마다 일꾼을 새로 만들어야 합니다.

- **멀티프로세스 (`fork`)**: 새로운 프로세스를 만드는 것은 **'자회사'를 하나 세우는 것**과 같습니다. 부모의 모든 메모리 구조(가상 메모리, 페이지 테이블 등)를 복사해야 하므로 매우 무겁고 시간이 많이 걸립니다.
    
- **멀티스레드 (`pthread_create`)**: 새로운 스레드를 만드는 것은 **'기존 팀에 팀원 한 명을 추가'**하는 것과 같습니다. 스택(개인 작업 공간)만 새로 할당해주면 되기 때문에 훨씬 가볍고 빠릅니다.
    

### 2. 문맥 교환 비용 (Context Switching Cost) 🧠

여러 일꾼이 번갈아 가며 일할 때 발생하는 전환 비용입니다.

- **멀티프로세스**: A 프로세스에서 B 프로세스로 전환하는 것은 **A 회사의 직원이 B 회사로 출근**하는 것과 같습니다. 메모리 맵(주소 공간) 자체가 완전히 바뀌므로, CPU의 캐시 메모리(단기 기억)를 상당 부분 비워야 하는 등 큰 비용이 발생합니다.
    
- **멀티스레드**: 같은 프로세스 내의 A 스레드에서 B 스레드로 전환하는 것은 **한 직원이 '기획' 업무를 하다가 '디자인' 업무로 바꾸는 것**과 같습니다. 같은 사무실(메모리 공간) 안에서 움직이므로 전환 비용이 훨씬 저렴합니다.
    

### 3. 메모리 공유 및 통신 (Memory Sharing and Communication) ⛓️

이것이 프록시에서 멀티스레드를 사용하는 가장 결정적인 이유입니다. 프록시는 캐싱(Caching) 기능을 구현해야 할 때가 많습니다.

- **멀티프로세스**: 각 프로세스는 **독립된 메모리 공간**을 가집니다. 만약 A 프로세스가 캐시한 데이터를 B 프로세스가 사용하려면, 공유 메모리(Shared Memory)나 파이프(Pipe) 같은 복잡하고 느린 프로세스 간 통신(IPC) 기술을 사용해야 합니다.
    
- **멀티스레드**: 모든 스레드는 **힙(Heap) 메모리 영역을 공유**합니다. 따라서 하나의 거대한 캐시 공간을 만들어두면, A 스레드가 캐시한 데이터를 B 스레드가 아무런 추가 비용 없이 **마치 자신의 변수처럼** 즉시 접근하여 사용할 수 있습니다. 이는 캐시 구현을 매우 간단하고 빠르게 만듭니다.
    

---

### ## 단점: 동기화 문제

물론 멀티스레드에도 단점은 있습니다. 모든 스레드가 메모리를 공유하기 때문에, 여러 스레드가 동시에 같은 데이터(예: 캐시)에 접근할 때 데이터가 엉키는 **경쟁 상태(Race Condition)**가 발생할 수 있습니다. 이를 막기 위해 뮤텍스(Mutex)나 세마포어(Semaphore) 같은 동기화 기법을 반드시 사용해야 하므로, 프로그래밍의 복잡도는 올라갑니다.

### ## 요약

|**특징**|**멀티프로세스 (fork)**|**멀티스레드 (pthread)**|
|---|---|---|
|**구현 난이도**|상대적으로 쉬움 (독립적)|복잡함 (동기화 필요)|
|**생성/전환 속도**|느림|**빠름**|
|**데이터 공유**|어려움 (IPC 필요)|**매우 쉬움 (메모리 공유)**|

결론적으로, 동기화 문제라는 복잡성을 감수하더라도, **속도와 효율적인 데이터 공유**라는 압도적인 장점 때문에 고성능 프록시 서버는 대부분 멀티스레드 모델을 채택합니다.