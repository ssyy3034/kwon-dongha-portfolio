---
date: 2025-10-31
tags: [CS]
---

### **Proxy Lab 구현 로드맵**

이 실습은 크게 3단계의 점진적인 개발 과정으로 나눌 수 있습니다.

#### **1단계: 기본 프록시 구현 (순차적 처리)**

**목표**: 우선 한 번에 한 명의 클라이언트 요청이라도 제대로 중계하는, 가장 기본적인 순차(Iterative) 프록시를 완성합니다.

1. **서버 초기화 및 연결 대기**:
    
    - `main` 함수에서 커맨드 라인 인자(`argv[1]`)로 포트 번호를 받습니다.
        
    - `open_listenfd`를 사용해 해당 포트에서 클라이언트의 연결을 기다리는 **리슨 소켓(`listenfd`)**을 엽니다.
        
    - `while(1)` 무한 루프를 시작합니다.
        
2. **클라이언트 연결 수락**:
    
    - `while` 루프 안에서 `accept`를 호출하여 클라이언트의 연결 요청을 기다립니다.
        
    - 연결이 수립되면, 클라이언트와 통신할 **연결 소켓(`connfd`)**을 얻습니다.
        
3. **HTTP 요청 파싱 (가장 중요한 부분)**:
    
    - `connfd`로부터 클라이언트가 보낸 HTTP 요청을 `Rio_readlineb`를 사용해 읽습니다. **우선 요청 라인(첫 번째 줄)만 먼저 읽습니다.**
        
    - 읽어온 요청 라인(예: `GET http://www.google.com/index.html HTTP/1.0`)을 파싱하여 세 가지 핵심 정보를 추출해야 합니다:
        
        - **메소드 (Method)**: `GET`
            
        - **URL**: `http://www.google.com/index.html`
            
        - **HTTP 버전**: `HTTP/1.0`
            
    - 파싱한 URL에서 다시 **호스트 이름(hostname)**, **포트 번호(port)**, **경로(path)**를 분리해야 합니다. (`sscanf`나 `strstr`, `strtok` 같은 문자열 함수를 활용해야 합니다. 포트 번호가 URL에 명시되지 않았다면 기본값인 `80`을 사용해야 합니다.)
        
4. **최종 서버로 요청 중계**:
    
    - 3단계에서 얻은 호스트 이름과 포트 번호를 사용하여, `open_clientfd`로 **최종 목적지 서버와의 연결**을 엽니다. 이렇게 해서 `serverfd`를 얻습니다.
        
    - 클라이언트로부터 읽었던 요청 라인과 헤더들을 **최종 서버(`serverfd`)**로 그대로 전달(`Rio_writen`)합니다.
        
        - **주의**: 요청 라인의 형식을 `GET [경로] HTTP/1.0` 형태로 바꾸고, `Host` 헤더를 포함하여 최종 서버에 보내야 합니다.
            
5. **서버 응답 중계**:
    
    - 최종 서버(`serverfd`)로부터 받은 응답을 `Rio_readnb` 또는 `Rio_readlineb`를 사용해 읽습니다.
        
    - 읽은 데이터를 **그대로** 클라이언트(`connfd`)에게 `Rio_writen`으로 전달합니다.
        
    - 서버가 연결을 끊을 때까지(읽기 함수가 0을 반환할 때까지) 이 과정을 반복합니다.
        
6. **연결 종료**:
    
    - 모든 데이터 전송이 끝나면, 사용했던 모든 소켓(`connfd`, `serverfd`)을 `close` 합니다.
        
    - `while` 루프의 처음으로 돌아가 다음 클라이언트를 기다립니다.
        

> **1단계 완료 후**: `driver.sh`를 실행하여 **'Basic'** 항목의 모든 테스트를 통과해야 합니다.

---

#### **2단계: 동시성 프록시 구현 (병렬 처리)**

**목표**: 1단계에서 만든 순차 프록시는 한 번에 한 명만 처리할 수 있습니다. 이제 여러 클라이언트의 요청을 **동시에** 처리할 수 있도록 멀티스레딩(Multi-threading)을 적용합니다.

1. **스레드 생성 로직 추가**:
    
    - `main` 함수의 `while` 루프 구조를 수정합니다.
        
    - 이제 `while` 루프는 **`accept`를 호출하여 `connfd`를 얻는 역할만** 합니다.
        
    - `connfd`를 얻는 즉시, 요청을 직접 처리하는 대신 **새로운 스레드를 생성(`pthread_create`)**하여 처리를 위임합니다.
        
2. **스레드 함수 작성**:
    
    - 스레드가 실행할 별도의 함수(예: `void *thread_routine(void *arg)`)를 만듭니다.
        
    - **1단계에서 `accept` 이후에 구현했던 모든 로직(파싱, 중계 등)을 이 `thread_routine` 함수 안으로 옮깁니다.**
        
3. **인자 전달**:
    
    - `pthread_create`는 스레드 함수에 단 하나의 인자(`void *`)만 넘겨줄 수 있습니다. `connfd`(정수)를 스레드에 안전하게 전달하려면, `malloc`으로 메모리를 할당하여 `connfd` 값을 저장하고 그 포인터를 넘겨주는 방식을 사용해야 합니다.
        
    - `thread_routine` 함수는 시작 부분에서 이 포인터를 다시 원래 타입으로 캐스팅하여 `connfd` 값을 얻고, 함수가 끝나기 전에 `free`를 호출하여 메모리를 해제해야 합니다.
        
4. **스레드 분리 (Detaching)**:
    
    - 메인 스레드는 생성된 자식 스레드가 끝날 때까지 기다릴 필요가 없습니다. `pthread_detach(pthread_self())`를 `thread_routine` 함수 시작 부분에 호출하여, 스레드가 종료될 때 스스로 자원을 정리하도록 만듭니다.
        

> **2단계 완료 후**: `driver.sh`를 실행하여 **'Concurrency'** 항목의 모든 테스트를 통과해야 합니다.

---

#### **3-A단계: 캐싱 프록시 구현 (성능 최적화)**

**목표**: 자주 요청되는 웹 객체를 프록시 메모리에 저장(캐싱)하여, 최종 서버까지 가지 않고 즉시 응답함으로써 속도를 높이고 서버 부하를 줄입니다.

1. **캐시 자료구조 설계**:
    
    - 캐시 데이터를 저장할 구조체를 정의합니다. (예: `struct cache_block`)
        
        - `url`: 캐시된 객체의 URL (Key 역할)
            
        - `content`: 실제 웹 객체의 내용 (Value 역할)
            
        - `size`: 콘텐츠의 크기
            
        - `timestamp`: LRU(Least Recently Used) 교체 정책을 위한 시간 정보
            
    - 이 구조체들의 배열이나 연결 리스트(Linked List)로 전체 캐시를 구성합니다. (`static` 전역 변수로 선언)
        
2. **캐시 접근 로직 구현 (in `thread_routine`)**:
    
    - 클라이언트의 요청 URI를 파싱한 직후, **가장 먼저 캐시를 탐색**합니다.
        
    - **Cache Hit (캐시에 데이터가 있을 경우)**:
        
        - 해당 URL과 일치하는 블록을 찾으면, 최종 서버로 연결하지 않습니다.
            
        - 캐시에 저장된 `content`를 즉시 클라이언트(`connfd`)에게 `Rio_writen`으로 전송하고 스레드를 종료합니다.
            
    - **Cache Miss (캐시에 데이터가 없을 경우)**:
        
        - 기존의 로직대로 최종 서버에 접속하여 응답을 받아옵니다.
            
        - 응답을 클라이언트에게 전달하는 **동시에**, 그 내용을 메모리 버퍼에 저장합니다.
            
3. **캐시에 데이터 쓰기**:
    
    - 최종 서버로부터 모든 응답을 받은 후, 응답의 전체 크기가 `MAX_OBJECT_SIZE`를 넘지 않는다면 캐시에 저장합니다.
        
    - 캐시에서 비어있는 공간을 찾아 저장하거나, 만약 꽉 찼다면 **교체 정책(Eviction Policy)**에 따라 가장 오래된 데이터를 삭제하고 그 자리에 새로운 데이터를 씁니다.
        

#### **3-B단계: 캐시 동시성 문제 해결**

**목표**: 여러 스레드가 동시에 캐시 자료구조에 접근할 때 발생할 수 있는 경쟁 상태(Race Condition)를 막습니다.

1. **뮤텍스(Mutex) 사용**:
    
    - 캐시를 보호하기 위한 전역 뮤텍스 변수(`pthread_mutex_t cache_mutex`)를 선언하고 초기화합니다.
        
    - **모든 캐시 읽기/쓰기 작업 전후**에 `pthread_mutex_lock()`과 `pthread_mutex_unlock()`을 호출하여, 한 번에 단 하나의 스레드만 캐시에 접근하도록 보장해야 합니다.
        
    - **예시**:
        
        - 캐시 탐색(읽기) 시작 전 `lock`, 끝난 후 `unlock`.
            
        - 캐시에 새로운 데이터 쓰기 시작 전 `lock`, 끝난 후 `unlock`.
            

> **3단계 완료 후**: `driver.sh`를 실행하여 **'Cache'** 항목까지 모든 테스트를 통과하면 실습이 완료됩니다.


[[프록시 서버 구현]]