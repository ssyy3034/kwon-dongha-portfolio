---
date: 2025-10-22
tags: [CS]
---

# 🧩 9.6.1 캐시와 가상 메모리의 통합 (Integrating Caches and VM)
## 1️⃣ 핵심 주제: 물리적 주소 지정의 선택

가상 메모리(VM)와 SRAM 캐시(L1, L2, L3)를 함께 사용하는 시스템에서는  
캐시에 접근할 때 **어떤 주소 체계**를 사용할지가 핵심적인 설계 결정이다.

- **대부분의 현대 시스템 선택:**  
  → **물리적 주소 지정 (Physical Addressing)** 사용  
  → 즉, **주소 변환이 먼저 이루어진 뒤 캐시 접근**이 수행된다.

> 💡 **핵심 포인트:**  
> MMU가 VA → PA 변환을 완료한 후,  
> 해당 **PA가 캐시로 전송되어 데이터가 조회**된다.  
> (그림 9.14의 순서 흐름: VA → MMU → PTE → PA → 캐시 → CPU)

---

## 2️⃣ 물리적 주소 지정 방식을 채택하는 이유

### 🧱 A. 공유의 용이성 (Ease of Sharing)

- 물리 주소를 기준으로 하면,  
  **여러 프로세스가 동일한 물리적 캐시 블록을 공유**할 수 있다.
- 즉, 서로 다른 프로세스라도  
  동일한 가상 페이지가 같은 물리 페이지를 가리킨다면  
  캐시에서도 동일한 블록을 참조하게 된다.

> 💡 이는 **VM의 목표(단일 복사본 유지)**와 일치한다.  
> — “공유 객체(shared object)”의 단일 복사본만 DRAM에 존재하도록 유지 가능.

---

### 🧩 B. 보호 문제의 분리 (Separation of Protection)

- 캐시 계층은 **접근 권한 검사(protection check)**를 신경 쓸 필요가 없다.  
- 보호 권한은 **MMU의 주소 변환 과정에서 이미 처리**된다.

MMU는 각 페이지의 **PTE(Page Table Entry)**에 저장된 권한 비트로 접근 여부를 판별한다.

| 비트    | 의미                 |
| ----- | ------------------ |
| SUP   | 슈퍼바이저(커널) 모드 접근 여부 |
| READ  | 읽기 권한              |
| WRITE | 쓰기 권한              |

> ❗ 보호 위반이 감지되면 MMU가 **보호 예외(protection fault)**를 발생시키고,  
> 커널이 **SIGSEGV 시그널**을 전달해 프로세스를 종료한다.  
> → 따라서 **캐시는 보호 문제를 완전히 신경 쓰지 않아도 된다.**

---

## 3️⃣ 통합 과정 요약 (그림 9.14 흐름 설명)

그림 9.14는 **물리 주소 기반 캐시가 VM과 통합되는 전체 순서**를 나타낸다.

### 🧭 단계별 흐름

1️⃣ **프로세서:**  
   가상 주소(VA)를 생성해 MMU로 전달한다.

2️⃣ **MMU: PTE 조회 (페이지 테이블 접근)**  
   - VA의 상위 비트(VPN)를 이용해 PTE의 주소를 계산한다.  
   - 필요한 PTE는 캐시나 주 메모리에서 가져온다.  
   - **💡 주의:** PTE 자체도 데이터이므로 **L1 캐시에 캐시될 수 있다.**

3️⃣ **MMU: 주소 변환 수행**  
   - PTE에서 **PPN(Physical Page Number)**을 읽어온다.  
   - VA의 하위 비트(VPO, Virtual Page Offset)**와 결합하여  
     **물리 주소(PA)**를 생성한다.

4️⃣ **캐시 접근:**  
   - 생성된 PA로 **캐시(L1/L2/L3)**를 조회한다.  
   - 캐시에 해당 블록이 존재하면(hit) 즉시 데이터 반환.  
   - 미스 시 주 메모리(DRAM) 접근.

5️⃣ **결과 반환:**  
   - 캐시나 메모리에서 가져온 데이터 워드를 CPU로 전달.

---

## ✅ 정리 요약

| 구분 | 설명 |
|------|------|
| 주소 체계 | 캐시는 **물리 주소(physical addressing)** 사용 |
| 이유 ① | 여러 프로세스 간 **공유 객체 관리 용이** |
| 이유 ② | 접근 권한은 **MMU 수준에서 처리**, 캐시는 단순화 |
| 흐름 | CPU → MMU (VA→PA 변환) → Cache (PA로 접근) → CPU |

---

# ⚡ 9.6.2 TLB를 사용한 주소 변환 가속화 (Speeding Up Address Translation with a TLB)

## 1️⃣ TLB 도입 배경 — 성능 병목

가상 메모리(VM) 시스템에서 주소 변환은 필수지만,  
그 과정은 심각한 성능 병목을 일으킨다.

- **문제:**  
  CPU가 가상 주소(VA)를 생성할 때마다  
  MMU(Memory Management Unit)는 해당 주소의 **PTE(Page Table Entry)**를  
  페이지 테이블에서(DRAM) 읽어와야 한다.

- **비용:**  
  PTE 접근이 메모리 접근을 필요로 하면  
  그 비용은 수십~수백 사이클에 달한다.  
  (L1 캐시에 있다면 줄어들지만, 여전히 무시할 수 없는 수준이다.)

> 💡 결론: 주소 변환 비용이 너무 크기 때문에,  
> **PTE 접근 자체를 캐시해야 한다.**

---

## 2️⃣ TLB의 개념과 구조

TLB는 **PTE 캐시**다.  
즉, 자주 사용하는 VPN→PPN 매핑을  
MMU 내부의 초고속 메모리에 저장해둔다.

- **위치:** MMU 칩 내부에 내장  
- **내용:** 각 엔트리가 하나의 PTE를 저장  
- **특징:** 가상 주소 지정 방식 (virtually addressed cache)
- **연관도:** 매우 높은 수준의 연관성 (보통 4-way 이상)

### 🧠 인덱싱 방식

TLB는 VA의 **VPN(Virtual Page Number)** 일부를 이용한다.

| 필드               | 설명                       |
| ---------------- | ------------------------ |
| TLBI (TLB Index) | 세트를 선택하는 인덱스 필드          |
| TLBT (TLB Tag)   | 특정 엔트리 일치 여부를 확인하는 태그 필드 |

즉, VPN의 일부가 인덱스로, 나머지가 태그로 사용된다.

---

## 3️⃣ TLB의 작동 과정

### ✅ 1. TLB Hit

가장 일반적인 경우.  
모든 주소 변환이 MMU 내부에서 즉시 처리된다.

1️⃣ CPU가 가상 주소(VA)를 생성  
2️⃣ MMU가 **TLB**에서 대응되는 PTE를 찾음  
3️⃣ PTE에서 얻은 **PPN(Physical Page Number)**과 **VPO(Virtual Page Offset)**을 결합해  
   물리 주소(PA)를 생성  
4️⃣ PA를 캐시에 전달 → 데이터 반환

> ⚙️ 전부 **온칩(on-chip)**에서 일어나기 때문에  
> 변환 속도는 거의 **1사이클 수준**이다.

---

### ❌ 2. TLB Miss

TLB에 해당 PTE가 없을 경우 다음 단계로 진행한다.

1️⃣ MMU가 L1 캐시나 메모리에서 PTE를 읽어옴  
2️⃣ 읽어온 PTE를 TLB에 저장 (기존 엔트리 교체 가능)  
3️⃣ 변환을 다시 시도하여 캐시 접근 수행

> 💡 즉, TLB 미스는 **PTE를 한 번 더 캐시하는 과정**으로 이해할 수 있다.

---

## 4️⃣ 실제 시스템 예시 — Intel Core i7

| 구성 | 설명 |
|------|------|
| L1 Instruction TLB | 128 엔트리 |
| L1 Data TLB | 64 엔트리 |
| 구조 | 4-way set associative |
| 캐시 접근 방식 | Virtually Addressed (VPN 기반) |

Core i7은 명령어용 TLB와 데이터용 TLB를 분리하여  
동시에 주소 변환을 수행할 수 있도록 최적화되어 있다.

---

## ✅ 핵심 요약

| 구분 | 설명 |
|------|------|
| 문제 | VA → PA 변환 시 PTE 접근 비용이 너무 큼 |
| 해결책 | MMU 내부에 PTE 캐시(TLB)를 둠 |
| 구조 | VPN 기반 가상 주소 지정, 고연관도 캐시 |
| 히트 시 | 주소 변환이 온칩에서 즉시 완료 |
| 미스 시 | PTE를 메모리/L1에서 가져와 TLB 갱신 |
| 실례 | Core i7: I-TLB(128), D-TLB(64), 4-way |

---
# 🔄 9.6.4 종단 간 주소 변환 (Putting It All Together)

## 1️⃣ 시스템 구성 및 가정

이 예시는 TLB와 L1 데이터 캐시가 존재하는 **소형 가상 메모리 시스템**을 모델로 한다.

| 구성 요소 | 설정 값 |
|------------|-----------|
| 주소 지정 | 바이트 단위 |
| 접근 단위 | 1 byte |
| 가상 주소(VA) | 14비트 (n = 14) |
| 물리 주소(PA) | 12비트 (m = 12) |
| 페이지 크기 | 64B (2⁶) |
| TLB | 4-way set associative, 16 entries |
| L1 D-cache | Direct-mapped, 4B 블록, 16세트 |
| 캐시 주소 방식 | 물리적 주소 지정 (physically addressed) |

---

## 2️⃣ 주소 포맷 분할

페이지 크기가 64B(2⁶)이므로, **하위 6비트는 페이지 오프셋**으로 사용된다.

| 구분 | 필드 | 비트수 | 설명 |
|------|------|--------|------|
| **가상 주소 (14비트)** | VPN | 8비트 | 가상 페이지 번호 |
|  | VPO | 6비트 | 가상 페이지 오프셋 |
| **물리 주소 (12비트)** | PPN | 6비트 | 물리 페이지 번호 |
|  | PPO | 6비트 | 물리 페이지 오프셋 |

> 💡 VPO = PPO (페이지 내부의 오프셋은 변환 없이 동일)

---

## 3️⃣ 하드웨어별 인덱싱 구조

### 🧠 TLB
- **입력:** VPN  
- **TLB Index (TLBI):** VPN의 하위 2비트  
- **TLB Tag (TLBT):** VPN의 상위 6비트  

### 💾 캐시
- **입력:** 물리 주소 (PA)  
- **Cache Offset (CO):** 하위 2비트  
- **Cache Index (CI):** 다음 4비트  
- **Cache Tag (CT):** 상위 6비트  

---

## 4️⃣ 예시: CPU가 VA = `0x03D4`를 읽을 때

CPU가 주소 `0x03D4`에서 1바이트를 읽는 과정을 단계별로 살펴보자.

### ① 가상 주소 디코딩
```
VA = 0000 0011 1101 0100₂ = 0x03D4  
VPN = 0x0F  
VPO = 0x14
```

---

### ② TLB 접근
- **TLBI = 0x3**, **TLBT = 0x3**  
- MMU는 VPN(0x0F)을 TLB에 보냄  
- TLB의 세트 3에서 태그 3을 찾는다.

✅ **TLB 히트:**  
- 매칭된 엔트리의 **PPN = 0x0D**를 얻음.  
- (TLB 미스라면, MMU가 메모리의 페이지 테이블에서 PTE를 찾아 TLB를 갱신해야 함)

---

### ③ 물리 주소 구성
```

PA = [PPN | PPO] = [0x0D | 0x14] = 0x354

```

즉, **물리 주소 0x354**가 생성된다.

---

### ④ 캐시 접근
캐시는 PA를 받아 다음 필드를 분리한다.

| 필드                | 값    | 설명           |
| ----------------- | ---- | ------------ |
| CO (Block Offset) | 0x0  | 블록 내 바이트 위치  |
| CI (Cache Index)  | 0x5  | 캐시 세트 선택     |
| CT (Cache Tag)    | 0x0D | 캐시 블록 식별용 태그 |

✅ **세트 5의 태그가 0x0D와 일치 → 캐시 히트**  
→ 데이터 반환.

---

### ⑤ 데이터 반환
캐시가 해당 블록의 오프셋 0에 있는 바이트(`0x36`)를 읽어  
MMU → CPU로 전달한다.

```

결과: CPU는 VA 0x03D4 → 실제 메모리 데이터 0x36을 획득

```

---

## 5️⃣ 다른 가능한 시나리오

이 예시는 TLB와 캐시가 모두 히트한 경우지만,  
다른 조합도 가능하다:

| 상황 | 동작 |
|------|------|
| **TLB Miss** | MMU가 메모리에서 PTE를 로드 후 TLB 갱신 |
| **TLB Hit + Cache Miss** | 변환된 PA를 이용해 DRAM에서 데이터 블록을 가져와 캐시에 저장 |
| **Page Fault** | PTE의 valid bit가 0 → OS가 디스크에서 페이지를 스왑인 |

---

## ✅ 전체 흐름 요약

```
CPU → VA 생성  
↓  
MMU(TLB 조회)  
↳ Hit → PPN 반환  
↳ Miss → Page Table 접근  
↓  
VA(VPO) + PPN → PA 생성  
↓  
Cache 접근  
↳ Hit → 데이터 반환  
↳ Miss → DRAM에서 로드  
↓  
CPU로 데이터 반환
```

# 🧠 9.7 Intel Core i7 / Linux 메모리 시스템

---

## 1️⃣ 개요: 하드웨어 + 운영체제의 협력 구조

Intel Core i7 프로세서에서 Linux가 가상 메모리(VM)를 관리하는 방식은  
**하드웨어(MMU, TLB, 캐시)** 와 **커널(mm_struct, vm_area_struct)** 의 긴밀한 협력을 통해 동작한다.

### ▪️ 주소 공간

|항목|크기|용량|
|---|---|---|
|가상 주소 (VA)|48비트|256 TB|
|물리 주소 (PA)|52비트|4 PB|
|페이지 크기|4 KB (Linux 기본)||

Core i7은 64비트 아키텍처지만, 현재는 **48비트 VA**, **52비트 PA**만 사용한다.  
32비트(4GB) 모드와의 하위 호환성도 유지한다.

---

## 2️⃣ 하드웨어 구성

- 각 코어는 **TLB 계층**, **L1/L2 캐시**, **공유 L3 캐시**, **DRAM 컨트롤러**를 포함한다.
    
- L1, L2, L3 캐시는 **물리 주소 지정(physically addressed)** 이며, 블록 크기는 64B이다.
    
- TLB는 **가상 주소 지정(virtually addressed)** 이며, 주소 변환 성능을 위해 존재한다.
    

### ▪️ TLB 구조 (4-way set associative)

| 종류        | 엔트리 수 | 역할            |
| --------- | ----- | ------------- |
| L1 i-TLB  | 128   | 명령어 주소 변환     |
| L1 d-TLB  | 64    | 데이터 주소 변환     |
| L2 통합 TLB | 512   | 명령어/데이터 통합 변환 |

---

## 3️⃣ 주소 변환 (Address Translation)

Core i7은 **4단계 페이지 테이블 구조**를 사용한다.  
각 프로세스는 독립적인 페이지 테이블 계층을 갖고,  
**CR3 레지스터**가 L1 테이블의 물리 주소를 가리킨다.

### ▪️ 가상 주소(VA) 구조 (48비트)

| 필드   | 크기   | 역할                                  |
| ---- | ---- | ----------------------------------- |
| VPN1 | 9비트  | L1 (PGD, Page Global Directory) 인덱스 |
| VPN2 | 9비트  | L2 (PUD, Page Upper Directory) 인덱스  |
| VPN3 | 9비트  | L3 (PMD, Page Middle Directory) 인덱스 |
| VPN4 | 9비트  | L4 (PT, Page Table) 인덱스             |
| VPO  | 12비트 | 페이지 내 바이트 오프셋 (4KB 페이지)             |

→ MMU는 이 4개의 VPN을 단계적으로 사용해 L1~L4 테이블을 탐색한다.  
→ L4의 PTE가 최종적으로 **물리 페이지 번호(PPN)** 를 포함한다.

---

## 4️⃣ 페이지 테이블 엔트리(PTE) 구조

| 비트  | 이름                   | 설명                      |
| --- | -------------------- | ----------------------- |
| P   | Present              | 페이지가 메모리에 존재하면 1        |
| R/W | Read/Write           | 쓰기 가능 여부                |
| U/S | User/Supervisor      | 사용자 모드 접근 가능 여부         |
| XD  | eXecute Disable      | 명령어 실행 금지 (버퍼 오버플로 방지)  |
| A   | Reference            | 접근 시 MMU가 자동으로 1로 설정    |
| D   | Dirty                | 쓰기 발생 시 MMU가 자동으로 1로 설정 |
| PPN | Physical Page Number | 물리 메모리 내 페이지의 주소        |

- **A 비트**는 페이지 교체 알고리즘에 사용됨.
    
- **D 비트**는 수정된 페이지를 디스크로 다시 써야 함을 표시.
    

---

## 5️⃣ 캐시와 가상 메모리의 통합

Core i7의 L1 캐시는 **주소 변환과 병렬로 동작**하여 속도를 높인다.

### ▪️ 핵심 원리

- 페이지 크기가 4KB → **VPO(12비트) = PPO(12비트)**
    
- 즉, 같은 페이지 내에서는 **가상 주소 하위 12비트와 물리 주소 하위 12비트가 동일**하다.
    

이 덕분에, CPU는 다음을 **동시에** 수행할 수 있다:

| 단계  | 설명                                                 |
| --- | -------------------------------------------------- |
| ①   | CPU가 VA 생성 → VPN(상위비트)는 MMU로, VPO(하위 12비트)는 캐시로 전달 |
| ②   | MMU는 VPN으로 TLB 조회 시작                               |
| ③   | L1 캐시는 VPO의 하위 비트로 세트 인덱스와 블록 오프셋 계산               |
| ④   | MMU가 TLB에서 PPN을 받는 동안 캐시는 세트 내 블록들(8-way)을 미리 읽음   |
| ⑤   | MMU가 PPN을 반환하면 캐시는 태그 비교 완료 → 바로 Hit/Miss 판단       |

즉,  
**주소 변환(MMU)과 캐시 접근(L1 Cache)** 이 **파이프라인처럼 중첩(overlap)** 되어 동작한다.

---

## 6️⃣ Linux의 가상 메모리 구조체

Linux 커널은 각 프로세스의 주소 공간을 관리하기 위해 다음 두 구조를 사용한다.

| 구조체              | 역할                                                                |
| ---------------- | ----------------------------------------------------------------- |
| `task_struct`    | 프로세스 제어 블록 (PCB). 실행 상태, 스케줄링 정보, `mm` 포인터 포함                     |
| `mm_struct`      | 프로세스의 전체 가상 메모리 레이아웃 관리. 페이지 테이블 포인터(`pgd`)와 VM 영역 리스트(`mmap`) 포함 |
| `vm_area_struct` | 하나의 연속된 가상 메모리 영역을 나타냄. (code, data, heap, stack 등)               |
|                  | 필드: `vm_start`, `vm_end`, `vm_prot`, `vm_flags` 등                 |
|                  |                                                                   |

→ 즉,  
**`mm_struct`는 주소 공간 전체를, `vm_area_struct`는 각각의 세그먼트를 표현한다.**

---

## 7️⃣ 페이지 폴트(Page Fault) 처리 과정

MMU가 VA를 변환하는 중, 해당 페이지가 메모리에 존재하지 않거나 권한이 맞지 않으면  
**페이지 폴트(page fault)** 예외가 발생한다.  
제어는 **커널의 페이지 폴트 핸들러**로 넘어간다.

### ⚙️ 단계별 동작

#### (1) 가상 주소 A의 합법성 검사

- `vm_area_struct` 리스트를 순회하며  
    VA가 어느 영역(`vm_start ≤ A < vm_end`)에도 속하지 않으면 →  
    **세그멘테이션 오류(SIGSEGV)** 발생 → 프로세스 종료.
    

#### (2) 접근 권한 검사

- 해당 영역의 `vm_prot` 필드 확인:
    
    - 읽기 전용인데 쓰기 시도?
        
    - 사용자 프로세스가 커널 영역 접근 시도?  
        → 위반 시 **보호 예외(protection fault)** 발생 → 프로세스 종료.
        

#### (3) 페이지 폴트 처리 및 명령어 재시작

- 접근이 합법하면:
    
    1. 커널이 **희생 페이지(victim page)** 선택  
        (dirty면 디스크에 기록)
        
    2. 디스크에서 필요한 페이지를 **DRAM으로 로드**
        
    3. **PTE 업데이트 (valid bit=1)**
        
    4. CPU 명령어 **재시작(restart)**  
        → 이번엔 페이지가 캐시에 있으므로 정상 수행.
        

---

## ✅ 정리 요약

| 단계  | 설명                             |
| --- | ------------------------------ |
| ①   | CPU가 VA 생성 → MMU가 TLB에서 PPN 탐색 |
| ②   | L1 캐시는 VPO로 세트 접근 (MMU 병행 진행)  |
| ③   | TLB Hit → PA 조립 후 캐시 태그 비교     |
| ④   | Page Fault 발생 시 커널의 3단계 핸들링 수행 |
| ⑤   | 페이지 로드 및 PTE 갱신 후 명령어 재시작      |

---

## 🧩 핵심 개념 요약표

| 구분     | 하드웨어                   | 소프트웨어                         |
| ------ | ---------------------- | ----------------------------- |
| 주소 변환  | MMU, TLB, 페이지 테이블      | 커널의 페이지 폴트 핸들러                |
| 메모리 보호 | PTE의 R/W, U/S, XD 비트   | `vm_prot` 검사                  |
| 메모리 구조 | L1/L2/L3 캐시, DRAM      | `mm_struct`, `vm_area_struct` |
| 페이지 교체 | MMU의 A/D 비트 → 커널 정책 반영 | LRU 등 교체 알고리즘 적용              |

# 🧠 9.8 메모리 매핑 (Memory Mapping)

---

## 1️⃣ 개념 — 디스크 객체와 가상 메모리 영역 연결

**메모리 매핑(Memory Mapping)** 은  
가상 메모리의 특정 영역(Virtual Memory Area, VMA)을  
디스크의 파일(regular file) 또는 익명 객체(anonymous object)와 **연결(mapping)** 하여  
해당 영역의 내용을 초기화하는 메커니즘이다.

Linux는 이 매핑 기능을 프로그래머에게 **`mmap()`** 시스템 콜 형태로 제공한다.

> 간단히 말해, “디스크 파일의 일부를 메모리에 올려서 주소처럼 접근하게 하는 것”이 메모리 매핑이다.

---

## 2️⃣ 매핑의 두 가지 대상

### ▪️ (1) 정규 파일 (Regular File)

- 실행 파일(`a.out`)이나 데이터 파일의 일부분이 **가상 주소 공간에 매핑**된다.
    
- 각 페이지는 파일의 한 조각(페이지 크기만큼)을 의미한다.
    
- **요구 페이징(demand paging)** 으로 작동 → CPU가 처음 접근할 때 비로소 DRAM으로 스왑 인된다.
    
- 만약 파일보다 큰 영역을 매핑하면 남은 부분은 **0으로 채워진다.**
    

---

### ▪️ (2) 익명 파일 (Anonymous File)

- 커널이 생성한, **모든 내용이 0인 특수 객체**이다.
    
- CPU가 해당 페이지를 처음 참조할 때:
    
    1. 커널은 물리 메모리의 희생 페이지(victim page)를 확보하고,
        
    2. 그 페이지를 0으로 초기화한 뒤,
        
    3. 페이지 테이블(PTE)을 갱신한다.
        
- 디스크 I/O가 발생하지 않기 때문에, 이를 **요구 제로 페이지(Demand-Zero Page)** 라고 부른다.
    

---

## 3️⃣ 스왑 공간과의 관계

- 한 번 메모리에 올라온 페이지는 이후 **커널이 관리하는 스왑 파일(swap file)** 과 연동되어  
    필요 시 스왑 인/아웃된다.
    
- 스왑 공간의 크기는 **프로세스가 가질 수 있는 가상 페이지 총량의 한계**를 결정한다.
    

---

## 4️⃣ 공유 객체 vs 사적 객체

메모리 매핑은 여러 프로세스 간에 객체를 어떻게 **공유하거나 분리할지**를 결정한다.

### ▪️ (1) 공유 객체 (Shared Object)

- 한 프로세스의 쓰기 내용이 **다른 프로세스에서도 보인다.**
    
- 변경 내용은 **디스크의 원본 파일에도 반영된다.**
    
- 여러 프로세스가 동일한 공유 객체를 매핑해도,  
    **물리 메모리에는 단 하나의 복사본만 존재한다.**
    

### ▪️ (2) 사적 객체 (Private Object)

- 변경 내용이 **다른 프로세스에게 보이지 않으며**,  
    디스크의 원본에도 반영되지 않는다.
    
- 대신 **Copy-on-Write (COW)** 방식을 사용한다.
    

---

## 5️⃣ Copy-on-Write (COW) 메커니즘

사적 객체는 초기에는 공유 객체처럼 **하나의 물리 복사본**만 가진다.  
하지만, 프로세스가 쓰기를 시도하면 다음과 같은 절차가 발생한다.

1. 커널이 해당 페이지의 **PTE를 읽기 전용(read-only)** 으로 표시한다.
    
2. 프로세스가 **쓰기(write)** 를 시도하면 **보호 오류(protection fault)** 발생.
    
3. 페이지 폴트 핸들러가 이 요청을 감지 →  
    **새로운 물리 페이지를 복사**한 뒤, 쓰기 가능한 상태로 갱신.
    
4. 명령어를 재실행하면, 이제 **독립된 복사본에 쓰기**가 수행된다.
    

> 즉, "진짜 복사"는 **필요할 때만**, 그것도 "쓰기 시점에" 발생한다.  
> 덕분에 메모리 낭비 없이 복사 비용을 늦출 수 있다.

---

## 6️⃣ 프로세스 관리에서의 활용

### ▪️ (1) `fork()` — 복사-시-쓰기 기반 프로세스 복제

- `fork()` 호출 시 커널은 부모의 `mm_struct`, `vm_area_struct`, 페이지 테이블을 **그대로 복사**한다.
    
- 단, 모든 페이지를 **읽기 전용 + COW 플래그**로 표시한다.
    
- 부모나 자식 중 한 쪽이 쓰기 시도 시 COW 발동 →  
    해당 페이지의 독립 복사본이 생성된다.
    

👉 `fork()`의 비용이 낮은 이유가 바로 **COW 덕분**이다.

---

### ▪️ (2) `execve()` — 새로운 프로그램 로드

`execve()`는 현재 프로세스를 새 프로그램으로 덮어쓰며, 다음 과정을 수행한다.

1. 기존 사용자 영역(`code`, `data`, `heap`, `stack`) 제거
    
2. 새 프로그램의 **코드/데이터 영역을 파일 매핑(file-backed)**
    
    - `.text`, `.data` 섹션은 **사적 COW 영역**으로 매핑
        
    - `.bss`, `heap`, `stack` 은 **익명 demand-zero 페이지**로 매핑
        
3. 동적 라이브러리(`libc.so` 등)는 **공유 영역(shared)** 으로 매핑
    
4. 프로그램 카운터(PC)를 **새 엔트리 포인트(entry point)** 로 설정
    

---

## 7️⃣ 사용자 수준 매핑 — `mmap()` 시스템 콜

```c
void *mmap(void *start, size_t length, int prot, int flags,
           int fd, off_t offset);
```

| 인수       | 설명                                              |
| -------- | ----------------------------------------------- |
| `start`  | 매핑 시작 주소 (일반적으로 NULL로 커널에 위임)                   |
| `length` | 매핑할 바이트 길이                                      |
| `prot`   | 접근 권한 — `PROT_READ`, `PROT_WRITE`, `PROT_EXEC`  |
| `flags`  | 매핑 방식 — `MAP_ANON`, `MAP_PRIVATE`, `MAP_SHARED` |
| `fd`     | 매핑할 파일의 디스크립터                                   |
| `offset` | 파일 내 매핑 시작 위치                                   |

→ `mmap()`은 “파일의 일부를 내 주소 공간에 올려줘”라는 요청이다.  
→ 매핑이 해제되면(`munmap()` 호출 시) 이후 접근은 **Segmentation Fault**를 유발한다.

---

## ✅ 요약

|구분|개념|예시|
|---|---|---|
|**정규 파일 매핑**|파일 내용이 페이지에 직접 매핑|실행 파일의 `.text`, `.data`|
|**익명 파일 매핑**|0으로 초기화된 가상 페이지|힙, 스택, BSS|
|**공유 매핑**|여러 프로세스가 동일한 물리 페이지 공유|공유 라이브러리|
|**사적 매핑 (COW)**|변경 시 개별 복사본 생성|`fork()` 후 부모/자식 간 분리|
|**mmap()**|사용자 수준에서 매핑 제어|메모리 기반 파일 입출력|

---

## 9.8.4 사용자 수준 메모리 맵핑: mmap 함수
### ## `mmap` 함수 개요

`mmap` 함수는 커널에 요청하여 새로운 가상 메모리 영역을 생성하고, 디스크 객체의 연속적인 청크(chunk)를 해당 영역에 매핑합니다.
#### ### `mmap` 인자 설명

- `start`: 새로운 가상 메모리 영역의 시작 주소에 대한 **힌트**. 보통 `NULL`로 지정하여 커널이 주소를 선택하게 합니다.
    
- `length`: 매핑할 객체 청크의 크기 (바이트).
    
- `prot`: 매핑된 영역의 **접근 권한**을 지정합니다.
    
    - `PROT_EXEC`: 페이지 내 명령어를 실행할 수 있습니다.
        
    - `PROT_READ`: 페이지를 읽을 수 있습니다.
        
    - `PROT_WRITE`: 페이지에 쓸 수 있습니다.
        
    - `PROT_NONE`: 페이지에 접근할 수 없습니다.
        
- `flags`: 매핑된 객체의 **유형**을 지정합니다.
    
    - `MAP_ANON`: **익명 객체(anonymous object)**를 매핑합니다. 이 경우 가상 페이지는 **요구-제로(demand-zero)** 페이지가 됩니다.
        
    - `MAP_PRIVATE`: **사설 복사-시-쓰기(private copy-on-write)** 객체를 매핑합니다.
        
    - `MAP_SHARED`: **공유 객체(shared object)**를 매핑합니다.
        
- `fd`: 매핑할 객체를 지정하는 **파일 디스크립터**.
    
- `offset`: 매핑할 청크가 파일의 시작 지점으로부터 떨어진 거리 (바이트).
    
