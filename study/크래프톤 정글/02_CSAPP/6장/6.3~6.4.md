---
date: 2025-10-11
tags: [CS]
---

  # 🧠 Chapter 6.3–6.4 — Memory Hierarchy & Cache Memories (나무위키풍 확장)

> **한 줄 요약**: 컴퓨터는 "빠르고-작고-비싸다" vs "느리고-크고-싸다"의 딜레마를 **계층(hierarchy)** 으로 풀어낸다. 그리고 그 핵심 키워드는 **지역성(locality)**, **블록(block)**, **히트/미스(hit/miss)**, **태그/인덱스/오프셋(tag/index/offset)** 이다. 이 네 가지를 이해하면 나머지는 전부 응용이다.

---

## 0. 이 문서 어떻게 읽으면 좋나

- **배경 → 지역성 → 캐시가 하는 일 → 주소 분해 → 매핑/교체/쓰기 정책 → AMAT → 실전 튜닝** 순서로 읽으면 흐름이 잡힌다.
    
- 수식이 나와도 겁먹지 말자. 대부분은 **정의에 가까운 공식**이라 안전하다.
    
- 예시는 C를 쓴다. (row-major, 즉 행이 연속이라는 전제)
    

---

## 1. 왜 메모리 계층이 필요한가 (Processor–Memory Gap)

- CPU는 수십 년간 **지수적으로 빨라졌고**, DRAM은 **느긋하게 빨라졌다**(선형적에 가까움).
    
- 결론: **메모리 접근이 병목**. CPU가 놀게 된다.
    
- 그래서 나온 게 **계층 구조**다. 위층은 작고 빠르고 비싸고, 아래층은 크고 느리고 싸다. 위층은 아래층의 **일부만 복사해 보관**한다(=캐시한다).
    

```
레지스터 → L1/L2/L3(온칩 SRAM) → 메인메모리(DRAM) → SSD/HDD → 네트워크/클라우드
(위로 갈수록 빠르고 작음, 아래로 갈수록 느리고 큼)
```

> **관리 주체**: 레지스터(컴파일러) / L1~L3(하드웨어) / 메인메모리(OS+HW) / 디스크·웹 캐시(소프트웨어)

---

## 2. 지역성(Locality): 캐시가 먹고사는 이유

쉽게 말해, 프로그램은 한 번에 **주소공간의 작은 조각(작업세트)** 만 몰아서 쓴다.

### 2.1 시간 지역성(Temporal)

- **최근에 쓴 것**을 **곧 또 쓴다**.
    
- 예: 누적 변수 `sum`, 루프 바디의 짧은 함수, 자주 호출되는 라이브러리 코드.
    

### 2.2 공간 지역성(Spatial)

- **가까운 주소**를 **연달아** 쓴다.
    
- 예: 배열 순차 접근, 직선적인 명령어 페치.
    

### 2.3 나쁜 예시(공간 지역성 붕괴)

```c
// C는 row-major. 열 먼저 돌면 망함
for (int j = 0; j < N; j++)
  for (int i = 0; i < N; i++)
    sum += a[i][j];
```

- 메모리에서 이웃하지 않은 원소를 **멀리멀리 점프**하며 읽는다 → **캐시 미스 폭증**.
    

> **팁**: 기본 전략은 항상 **stride-1**(연속 접근)이다. 힘들면 루프 순서를 바꾸자(**loop interchange**).

---

## 3. 캐시가 실제로 하는 일(General Caching)

핵심은 단 두 줄.

1. 데이터는 **블록(block)** 단위로 위·아래 계층 사이에서 왔다 갔다 한다.
    
2. **Hit**면 빠르게 끝, **Miss**면 아래에서 블록을 **통째로** 끌어와 저장한 뒤 준다.
    

### 3.1 용어 정리

- **Hit**: 요청한 주소가 캐시에 있다.
    
- **Miss**: 없다. 아래 계층으로 내려간다.
    
- **Eviction**: 캐시가 꽉 차서 뭘 내보내야 한다.
    
- **블록(Line)**: 캐시가 한 번에 싣고 내리는 최소 단위(보통 64B).
    

### 3.2 미스의 3종(Three Cs)

- **Compulsory(Cold)**: 그 블록 **처음** 만지면 한 번은 미스 난다.
    
- **Capacity**: 작업세트가 캐시 **용량보다 크다**.
    
- **Conflict**: 서로 다른 블록이 **같은 세트**에만 들어갈 수 있어 **자리싸움**이 난다(특히 direct-mapped).
    

> **주의(실전)**: 파워오브투 크기의 배열 2개를 같은 간격으로 번갈아 읽으면 **같은 세트**만 때려서 스래싱이 난다. **패딩**을 조금 넣어 세트를 어긋나게 만들면 해결되는 경우가 많다.

---

## 4. 주소는 어떻게 찾는가(Tag/Index/Offset)

메모리 주소는 이렇게 쪼갠다:

```
| Tag (t) | Set Index (s) | Block Offset (b) |
```

- **Offset (b)**: 블록 안에서의 바이트 위치(`B = 2^b`).
    
- **Index (s)**: 어떤 **세트(set)** 로 갈지(`S = 2^s`).
    
- **Tag (t)**: 세트 안에서 **정확히 어떤 라인**인지 표지(`t = m − (s+b)`).
    

### 4.1 탐색 3단계(읽기)

1. 인덱스로 **세트 선택**
    
2. 세트 안 라인들의 **valid+tag 비교**
    
3. 오프셋으로 **원하는 바이트/워드 선택**
    

> 관례 공식: **C = S × E × B** (데이터 배열 기준). `E`는 세트당 라인 수(연관도). 메타데이터(valid/tag/dirty)는 별도 오버헤드.

### 4.2 소소하지만 중요한 디테일

- 인덱스는 보통 **중간 비트**에서 뽑는다. 상위 비트로만 뽑으면 큰 연속 메모리가 **같은 세트**로 몰려 충돌이 심해진다.
    
- 태그/상태 비트도 **SRAM**에 저장된다. 큰 캐시는 태그만 해도 은근 용량이 든다(오버헤드 계산 습관 들이자).
    

---

## 5. 캐시 클래스(Placement): Direct vs Set-Assoc vs Fully

|방식|한 줄 설명|장점|단점|
|---|---|---|---|
|**Direct-mapped (E=1)**|세트당 1칸|단순, 빠름|**충돌 미스 많음**|
|**Set-associative (E>1)**|세트당 E칸|충돌 완화, 현실적|태그 병렬 비교로 **히트 타임 증가** 가능|
|**Fully-associative (S=1)**|어디든 저장|충돌 최소|제일 비싸고 느림(보통 TLB처럼 **작은 캐시**에 씀)|

> 중간 지대가 바로 **N-way set associative**. 현대 CPU의 주력.

### 5.1 Direct-mapped가 유난히 아픈 경우

- 두 데이터 스트림이 **같은 인덱스**에만 계속 매핑되면 미스→필→퇴출이 반복되는 **스래싱**.
    
- 해결: 데이터에 **패딩** 주기, 배열 크기/정렬 조정, 혹은 연관도 높은 캐시.
    

### 5.2 보너스: Victim Cache(한 줄 맛보기)

- Direct-mapped 앞에 **작은 fully-assoc 버퍼**를 두어 방금 퇴출된 라인을 잠깐 붙잡아 둔다. 충돌 미스를 값싸게 줄일 때 쓰는 트릭.
    

---

## 6. 교체 정책(Replacement)

- **Random**: 단순, 의외로 못 미더울 정도로 평균은 한다.
    
- **FIFO**: 먼저 들어온 게 먼저 나감. 최근성 반영이 약함.
    
- **LRU**: 가장 오래 안 쓴 것 제거. 품질 좋지만 **비용↑**(특히 E가 클수록). 그래서 보통 **Pseudo-LRU(Tree-PLRU)** 같은 근사법을 쓴다.
    
- L1은 **히트타임**이 절대적이라 너무 복잡한 정책은 손해가 될 수 있다. L3처럼 큰 캐시는 더 똑똑한 정책(RRIP 등)을 쓰기도 한다.
    

---

## 7. 쓰기 정책(Write Policies)

### 7.1 쓰기 자체의 두 가지

- **Write-through**: 캐시와 메모리 **동시에** 씀. 구현 단순/일관성 좋음, **버스 트래픽↑**.
    
- **Write-back**: 캐시에만 표시(**dirty bit**)하고 내보낼 때 메모리에 반영. 트래픽↓, 복잡도↑.
    

### 7.2 미스 시 행동(allocate?)

- **Write-allocate**: 미스면 **블록을 끌어온 뒤** 쓴다(공간 지역성 활용).
    
- **No-write-allocate**: 블록은 안 끌고 **아래로 바로** 쓴다.
    

> 흔한 조합: **Write-back + Write-allocate**(메인스트림), **Write-through + No-write-allocate**(단순/내장기기 등).

### 7.3 현장 디테일(알아두면 득)

- **Write buffer**: write-through의 트래픽/지연을 줄이는 완충.
    
- **Write combining**: 인접한 소규모 쓰기를 합쳐 한 번에 전송.
    
- **Non-temporal(Streaming) store**: "다시 안 쓸" 대량 데이터는 **캐시를 건너뛰어** 오염을 막는다.
    
- **RFO(Read For Ownership)**: write-allocate에서 저장 전 해당 블록을 **읽어와 소유권**을 잡는 절차.
    

---

## 8. 미스 처리와 채움(Fill) 최적화

- **Critical-word-first**: 필요한 워드부터 먼저 가져와 빨리 재개.
    
- **Early restart**: 필요한 워드가 오면 나머지 라인을 기다리지 않고 실행 재개.
    
- **MSHR(Non-blocking cache)**: 미스가 처리되는 동안에도 **다른 요청**을 더 보낼 수 있게 하는 구조(동시 미스 추적 엔트리).
    

---

## 9. 성능 지표와 AMAT(평균 접근 시간)

- **Hit time**: 캐시에서 히트 판정+데이터 꺼내는 데 걸리는 시간.
    
- **Miss rate**: 미스 비율(=1−hit rate).
    
- **Miss penalty**: 미스 시 아래 계층 왕복 비용.
    

### 9.1 단일 레벨 AMAT

```
AMAT = Hit time + Miss rate × Miss penalty
```

### 9.2 다단계 AMAT(대표식)

```
AMAT(L1) = t1 + m1 × ( t2 + m2 × ( t3 + m3 × DRAM ) )
```

- 여기서 `t`는 히트타임, `m`은 미스레이트. L3 미스면 DRAM 패널티까지 간다.
    

### 9.3 숫자 감

- L1 히트: 수 사이클
    
- L1→L2 미스 패널티: 대략 10c 언저리
    
- L1→L3: 수십 c
    
- DRAM: 수백 c (세대/클록/메모리/인터커넥트에 따라 달라짐)
    

---

## 10. 파라미터 셋업/계산 예시(연습용)

**가정**: 32-bit 주소(`m=32`), L1 d-cache `C=32KB`, `B=64B`, `E=8`.

1. 세트 수 `S = C / (E×B) = 32768 / (8×64) = 64` → `s = log2 64 = 6`
    
2. 블록 오프셋 `b = log2 64 = 6`
    
3. 태그 비트 `t = m − (s+b) = 32 − 12 = 20`
    

**주소 형태**: `| t=20 | s=6 | b=6 |`

### 10.1 메타데이터 오버헤드 감각

- 총 라인 수: `C/B = 32768/64 = 512`라인.
    
- 세트당 8라인(E=8) → 세트는 64개.
    
- 각 라인 태그 20b + valid/dirty 등 상태비트(대충 몇 비트) → **데이터 외에도 꽤 공간을 먹는다**는 포인트만 기억해두자.
    

---

## 11. 캐시 친화적 코드 레시피(현장에서 바로 쓰는 체크리스트)

**기본기**

- **배열 순차 접근(stride-1)** 을 최우선으로. 하드웨어 프리패처가 제일 잘 먹힌다.
    
- **루프 교환(loop interchange)** 으로 stride-1 만들기.
    
- **블로킹/타일링(blocking/tiling)** 으로 작업세트를 캐시에 가둬두기.
    
- **데이터 레이아웃**: 연결리스트처럼 포인터 점프가 많은 구조는 **공간 지역성 최악**. 가능하면 **배열**로 바꿔라.
    
- **AoS→SoA 전환**: 벡터화·캐시 효율을 위해 필요 필드만 연속화.
    

**세트 충돌 대응**

- 배열 뒤에 **패딩**으로 인덱스 어긋나게.
    
- 파워오브투 크기를 계속 쓰면 위험. 살짝 크기를 틀거나 정렬을 다르게.
    

**다중 스레드(살짝 맛보기)**

- **False sharing** 금지: 서로 다른 스레드가 **같은 캐시라인**의 이웃 필드를 툭툭 치면 성능이 녹아내린다. 라인 크기(예: 64B)만큼 **패딩**.
    

**스트리밍/대용량**

- 결과를 **다시 안 읽을** 큰 메모리 복사는 **non-temporal store**(스트리밍 저장) 사용 고려.
    

---

## 12. 흔한 오해 Q&A

- **Q. 캐시는 클수록 무조건 빠른가?**  
    A. 아니다. **L1은 히트타임**이 생명이다. 너무 키우면 오히려 느려진다. 그래서 L1<L2<L3로 나뉜다.
    
- **Q. 블록은 클수록 좋은가?**  
    A. 공간 지역성에는 좋지만, 라인 수가 줄어 **capacity/conflict 미스**가 늘 수 있고 **전송 지연**도 커진다. 현실은 **절충(예: 64B)**.
    
- **Q. 연관도(E)는 높을수록 좋은가?**  
    A. 충돌 미스는 줄지만 **태그 비교/제어 복잡**으로 히트타임이 길어진다. 역시 절충.
    
- **Q. 왜 L1을 I-cache/D-cache로 나눔?**  
    A. 명령어와 데이터를 분리하면 **경합 감소**·**튜닝 용이**, 파이프라인이 **둘을 병렬로** 끌어올 수 있다.
    

---

## 13. (옵션) 더 가보자 — 살짝 다음 장 맛보기

- **포용성 정책(Inclusive/Exclusive/Neither)**: L3가 L1/L2를 **포함**할지 말지의 전략. 디버깅/일관성/교체에 영향.
    
- **캐시 일관성(Coherence)**: 멀티코어에서 공유 데이터를 어떻게 동기화할지의 문제(MESI 등 프로토콜). 이 문서의 범위를 넘어가니 키워드만 챙겨두자.
    

---

## 14. 최종 체크 포인트

- **지역성**: 시간+공간. 가능한 한 **stride-1**.
    
- **주소 분해**: `|tag|index|offset|`, `C=S×E×B`.
    
- **Three Cs**: compulsory/capacity/conflict.
    
- **쓰기 정책**: write-back + write-allocate가 보편.
    
- **AMAT**: `Hit time + Miss rate × Miss penalty`.
    
- **튜닝 습관**: 루프 교환, 블로킹, 패딩, 레이아웃 변경, 스트리밍 저장.
    

> 여기까지 잡히면 6.3/6.4의 80%는 끝. 남은 20%는 **디테일을 상황에 맞게 적용**하는 감각이다. 실제 코드에서 **작업세트와 접근 패턴**을 눈으로 그려보는 습관을 들이면 금방 늘어난다.